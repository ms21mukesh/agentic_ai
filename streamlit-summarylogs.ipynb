{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import ollama\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hashlib\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./log_db\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(name=\"oracle_logs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and extract text from HTML logs\n",
    "def extract_text_from_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"meta\", \"head\", \"noscript\"]):\n",
    "        tag.extract()\n",
    "    clean_text = soup.get_text(separator=\" \").strip()\n",
    "    return \" \".join(clean_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute embeddings\n",
    "def compute_embedding(text):\n",
    "    return embedding_model.encode([text])[0].tolist()\n",
    "\n",
    "# Function to chunk text into smaller parts\n",
    "def chunk_text(text, chunk_size=2000):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_all_logs():\n",
    "    try:\n",
    "        # Retrieve all document IDs\n",
    "        all_docs = chroma_collection.get()  # Fetch all stored entries\n",
    "        if \"ids\" in all_docs and all_docs[\"ids\"]:\n",
    "            chroma_collection.delete(ids=all_docs[\"ids\"])  # Delete all by ID\n",
    "            st.session_state.clear()  # Reset UI state\n",
    "            st.success(\"üóë Cleared all logs and embeddings from ChromaDB.\")\n",
    "        else:\n",
    "            st.warning(\"‚ö†Ô∏è No logs found to clear.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ö†Ô∏è Error clearing logs: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store logs in ChromaDB\n",
    "def store_log_chunks(log_text):\n",
    "    chunks = chunk_text(log_text)\n",
    "    chunk_ids = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk_hash = hashlib.md5(chunk.encode()).hexdigest()\n",
    "        emb = compute_embedding(chunk)\n",
    "        chroma_collection.add(ids=[chunk_hash], embeddings=[emb], documents=[chunk])\n",
    "        chunk_ids.append(chunk_hash)\n",
    "\n",
    "    st.success(f\"‚úÖ Indexed {len(chunks)} log chunks in ChromaDB\")\n",
    "    return chunk_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve similar logs\n",
    "def retrieve_similar_logs(query_text, top_k=3):\n",
    "    query_embedding = compute_embedding(query_text)\n",
    "    results = chroma_collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
    "\n",
    "    if results[\"documents\"] and len(results[\"documents\"][0]) > 0:\n",
    "        return results[\"documents\"][0]\n",
    "\n",
    "    st.warning(\"‚ö†Ô∏è No relevant logs found. Processing new logs.\")\n",
    "    return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Prompts for different log types with user input**\n",
    "def get_prompt(file_type, log_text, user_summary):\n",
    "    user_summary_text = f\"### **User Provided Summary:**\\n{user_summary}\\n\\n\" if user_summary.strip() else \"\"\n",
    "\n",
    "    if file_type == \"awr\":\n",
    "        return f\"\"\"\n",
    "        {user_summary_text}\n",
    "        You are an Oracle Database expert. Analyze the following AWR report and provide insights:\n",
    "\n",
    "        ### **Key Metrics**\n",
    "        - Highlight critical performance indicators (DB Time, Wait Events, Top SQLs, I/O, CPU Usage).\n",
    "        - Identify unusual spikes or trends.\n",
    "\n",
    "        ### **Top 3 Issues**\n",
    "        - List the top 3 performance bottlenecks.\n",
    "        - Explain the root cause of each issue.\n",
    "        - Suggest actionable recommendations.\n",
    "\n",
    "        ### **Overall Summary**\n",
    "        - Summarize key findings in simple terms.\n",
    "        - Mention any configuration inefficiencies.\n",
    "\n",
    "        **Report Data:**\n",
    "        {log_text}\n",
    "        \"\"\"\n",
    "\n",
    "    elif file_type in [\"log\", \"trace\", \"alert\"]:\n",
    "        return f\"\"\"\n",
    "        {user_summary_text}\n",
    "        You are an Oracle Database expert. Analyze the following log file:\n",
    "\n",
    "        ### **Error Analysis**\n",
    "        - Identify critical **ORA-XXXX** errors, warnings, or unusual messages.\n",
    "        - Provide probable root causes.\n",
    "\n",
    "        ### **Impact & Severity**\n",
    "        - Explain how these errors affect database operations.\n",
    "        - Indicate whether it's critical or minor.\n",
    "\n",
    "        ### **Recommended Fixes**\n",
    "        - Suggest solutions to resolve the issues.\n",
    "        - Mention best practices or parameter tuning.\n",
    "\n",
    "        **Log Data:**\n",
    "        {log_text}\n",
    "        \"\"\"\n",
    "\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        {user_summary_text}\n",
    "        You are an Oracle expert troubleshooting database issues. Analyze the following logs:\n",
    "\n",
    "        ### **Root Cause Analysis**\n",
    "        - Identify the primary issue based on log patterns.\n",
    "        - Correlate errors with performance or configuration problems.\n",
    "\n",
    "        ### **Potential Causes**\n",
    "        - List possible reasons (e.g., resource contention, memory pressure, storage bottlenecks).\n",
    "        - Indicate if tuning or infrastructure fixes are needed.\n",
    "\n",
    "        ### **Next Steps & Recommendations**\n",
    "        - Suggest diagnostic steps (e.g., check V$ views, AWR, ADDM).\n",
    "        - Provide immediate and long-term solutions.\n",
    "\n",
    "        **Log Data:**\n",
    "        {log_text}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize logs using LLM\n",
    "def get_summary(model, relevant_chunks, file_type, user_summary):\n",
    "    if not relevant_chunks:\n",
    "        return \"‚ö†Ô∏è No relevant logs found. Please upload a valid log file.\"\n",
    "\n",
    "    combined_text = \"\\n\".join(relevant_chunks[:3])\n",
    "    prompt = get_prompt(file_type, combined_text, user_summary)\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = ollama.chat(model=model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        execution_time = time.time() - start_time\n",
    "        st.success(f\"‚úÖ Summary generated in {execution_time:.2f} seconds\")\n",
    "\n",
    "        return response[\"message\"][\"content\"] if \"message\" in response else \"No summary generated.\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error generating summary: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 08:26:34.667 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-01 08:26:34.668 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "# Streamlit UI\n",
    "st.title(\"‚ö° Oracle Log Summarizer with Issue Context\")\n",
    "\n",
    "# Model selection\n",
    "model = st.selectbox(\"Choose Model:\", [\"mistral:latest\", \"command-r-plus:latest\", \"llama3:latest\"], index=2)\n",
    "\n",
    "# User's issue summary\n",
    "user_summary = st.text_area(\"üìù Provide Your Issue Summary (Optional):\", height=100)\n",
    "\n",
    "# File upload or text input\n",
    "uploaded_file = st.file_uploader(\"Upload Log File (.log, .txt, .html, .awr)\", type=[\"log\", \"txt\", \"html\", \"awr\"])\n",
    "log_text = \"\"\n",
    "file_type = \"\"\n",
    "\n",
    "if uploaded_file:\n",
    "    file_type = uploaded_file.name.split(\".\")[-1]\n",
    "    content = uploaded_file.getvalue().decode(\"utf-8\")\n",
    "\n",
    "    if file_type == \"html\":\n",
    "        log_text = extract_text_from_html(content)\n",
    "        st.success(\"‚úÖ Extracted and cleaned HTML log.\")\n",
    "    else:\n",
    "        log_text = content\n",
    "else:\n",
    "    log_text = st.text_area(\"Paste Oracle Log Data:\", height=250)\n",
    "\n",
    "# Process log and store embeddings\n",
    "if st.button(\"Process Log\"):\n",
    "    if log_text.strip():\n",
    "        clear_all_logs()  # Ensure fresh analysis\n",
    "        store_log_chunks(log_text)  # Store new logs in ChromaDB\n",
    "\n",
    "        # Retrieve new logs for summarization\n",
    "        similar_logs = retrieve_similar_logs(log_text)\n",
    "\n",
    "        if not similar_logs:\n",
    "            st.warning(\"‚ö†Ô∏è No relevant logs found after processing. Please upload a valid log file.\")\n",
    "        else:\n",
    "            with st.spinner(\"Generating summary...\"):\n",
    "                st.session_state[\"summary_text\"] = get_summary(model, similar_logs, file_type, user_summary)\n",
    "\n",
    "# Display summary\n",
    "if \"summary_text\" in st.session_state:\n",
    "    st.subheader(\"üìÑ Log Summary:\")\n",
    "    st.text_area(\"Summary Output\", st.session_state[\"summary_text\"], height=200)\n",
    "\n",
    "# Clear logs button\n",
    "if st.button(\"üóë Clear Logs\"):\n",
    "    clear_all_logs()\n",
    "    st.rerun()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
